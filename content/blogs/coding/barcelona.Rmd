---
title: "Airbnb Analytics"
author: "Vasileios Papoutsoglou"
date:
output: html_document
slug: barcelona
categories:
- ''
- ''
---

# Airbnb Analytics - A Case Study about Barcelona Listings

**Note:** this work was part of a group project of seven. 

---



```{r setup, include=FALSE}
# leave this chunk alone
options(knitr.table.format = "html") 
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
  comment = NA, dpi = 300)
```


```{r load-libraries, echo=FALSE}

library(tidyverse) # the usual stuff: dplyr, readr, and other goodies
library(lubridate) # to handle dates
library(GGally) # for correlation-scatter plot matrix
library(ggfortify) # to produce residual diagnostic plots
library(rsample) # to split dataframe in training- & testing sets
library(janitor) # clean_names()
library(broom) # use broom:augment() to get tidy table with regression output, residuals, etc
library(huxtable) # to get summary table of all models produced
library(kableExtra) # for formatting tables
library(moderndive) # for getting regression tables
library(skimr) # for skim
library(mosaic)
library(leaflet) # for interactive HTML maps
library(tidytext)
library(viridis)
library(vroom)
library(corrplot)
```

# Executive Summary

## Overview
The purpose of this memo is to explore data on Airbnb listings in Barcelona and understand the key drivers of price, from the viewpoint of 2 people looking to visit the city for 4 nights.

## Methodology
What is the best model to predict the price of 2 adults visiting Barcelona for 4 nights?

We started our project with Exploratory Data Analysis (EDA), which offered insights into the types, content, and relevance of the existing variables. We then progressed to our models, after checking for the correlation of our independent variables, in order to find an optimal regression model that will predict the price.


## Findings 

### Exploratory Data Analysis

This section explores the steps we have taken to tidy and understand the data:

- Data Wrangling, since not all variables were of the appropriate type
- Rejection of variables that were incomplete or only had "NA" observations
- Adjusted the levels of some variables by clustering and categorising them
- Created new cleaned variables 
- Excluded NA observations in the variables we deemed relevant 

After selecting and adjusting relevant variables, we created summary statistics, charts, tables, and correlation matrices to visualise the data. During that, we concluded some correlation between *[insert findings]*

### Regression Analysis

This section showcases our work on examining relevant independent variables and constructing a number of different regression models to identify the optimal model, which should be the one which explains the highest portion of variance in the price of Airbnb listings in Barcelona.

#### Optimal Model

- Predictor variables across the following categories: 
prop_type_simplified
review_scores_rating
room_type
minimum_nights
bathrooms
bedrooms
accommodates
instant_bookable
neighbourhood_simplified
availability_30
reviews_per_month
host_is_superhost
host_response_rate
host_acceptance_rate
review_scores_cleanliness
review_scores_checkin
review_scores_location
review_scores_value


- Problematic collinearity: We include several variables from the same category in our price prediction model. There is no significant collinearity problem for our model, since, statistically, we have Square of GVIF^(1/(2*DF)) less than 5, which suggests there is no significant collinear relationships between our variables used for price prediction. 
However, there might be some further adjustments to out best model to improve the R-square for better price prediction, such as including more factors in some other different categories and also to make sure the collinearity of our variables become as small as possible. 


- The estimated stay for 2 adults spending four nights in Barcelona would cost is 835.0494, with 95% confidence interval of [512.9052,1613.538].


# Loading the Data


```{r load_data, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}

# use cache=TRUE so you dont donwload the data everytime you knit

listings <- vroom("http://data.insideairbnb.com/spain/catalonia/barcelona/2021-09-10/data/listings.csv.gz") %>% 
       clean_names()

```

# Exploratory Data Analysis

In our EDA, we will attempt to answer to following questions:

1. Which variables are relevant?
2. Does the data need cleaning?
3. Do we have outliers which we need to exclude?
4. Are there variables we need to convert?
5. Are there any additional variables we need to create based on the manipulation of existing data?
6. What is the relationship between the relevant variables? (Through this, we want to examine how successfully independent variables explain dependent variables)
7. What are the dependent and independent variables?`review_scores_rating`: Average review score (0 - 100)
 

## Raw Values

We use glimpse() to have a look at the data. There are 16,206 observations across 74 variables and presumably we might not actually need all of them, because some might be overlapping and some irrelevant.

```{r, glimpse data frame}
glimpse(listings)
```

We use skim() to identify missing values, and get a better picture of the data set. We make the following observations:
- Some numeric variables are listed as character
- There are a lot of missing values for character and numeric variables
- Especially for the ratings, a lot of values are missing
- There are many irrelevant variables



```{r, skim data frame}
skim(listings)
```


## Answering our EDA Questions - some of the steps we have taken below 

- Some of the pieces of data are of the wrong type or contain irrelevant data. For example, "price" is not only a "character" variable, but also contains the troublesome "$" symbol, which must be removed before proper analysis can begin. Also, the "bathrooms_text" data seems to be of use to our analysis, but first we need to once again turn it into a double-type data and remove the pesky text from it.

- Some of the listings are located in irrelevant cities or countries. The "host_location" variable has observations of listings which are not located in Barcelona, and as such we must filter out pieces of data from irrelevant locations in the data frame.

- There are some variables that seem rather irrelevant. For example, the "last_scraped" data, "name" and other such data seem a bit useless for analytical purposes, so we have to filter them out.

- There are NA values which we must omit for our analysis to be as accurate as possible.

- For the convenience of coding, comparing data and analysing, we converted the following 4 variables to numeric: price, bathrooms_text, host_response_rate, host_acceptance_rate.

- We created "property_type" by grouping data into 5 categories based on frequency distribution to control from the largest subgroups. Our 5 categories are "Entire rental unit","Private room in rental unit", "Entire serviced apartment","Entire condominium (condo)", “Other”.

- We created "neighbourhood_group_cleansed" by categorizing neighbourhoods into 4 different categories: North, Center, Coastal Line and West. 

- In addition, we created 5 data frames: host_specific, property_specific, reviews_specific, logical_specific, categorical_specific. For each of the 5 data frames, we have an overview of distribution and characteristics of each variable to see which variables might have the strongest power of predicting the price. 

- In the correlation matrix, blue represents for positive correlation and red represents for negative correlation. The darker the color is, the stronger the correlation between the variables. From our correlation matrix graph, we can see that the correlations between any two of bedroom, beds and accommodates are positive and relatively high. Also, another group of variables has relatively high positive correlation is the review-related variables, such as review scores cleanliness, review scores checkin, review scores communication, review scores location and review scores value. I think it is reasonable since these variables all describe reviews so they are somehow link to each other. Otherwise, variables have relatively weak negative correlation as indicated by very light red colour.

- Price is the dependent variable, while factors that might influence the price and people's preferences regarding the Barcelona AirBnB are independent variable, for example, property type, number of reviews, neighbourhood and so on.

## Creating our working data frame: Barcelona

We start out by cleansing out the entire data frame for only entries in which "Barcelona" is mentioned so that henceforth we know we are only wrangling relevant geographical data.

```{r, create Barcelona data frame and filter for correct location}

barcelona <- listings %>% 
  filter(host_location %in% c("Barcelona", 
                              "BARCELONA", 
                              "Barcelona, Barcelona, Spain", 
                              "Barcelona, BARCELONA, Spain",
                              "Barcelona, Catalonia, Spain",
                              "Barcelona, Cataluña, Spain",
                              "Barcelona, Catalunya, Spain")) 
 
```



Having done this, we can now filter out the data frame for specific variables that we wish to analyse, turn the problematic pieces of data into their correct data types, and remove the NA data from our frame (thus fixing the other issues mentioned above). After thorough consideration, we decided that the factors which are most interesting and relevant to our EDA are in relation to the characteristics of the hosts themselves and their properties. 

```{r, select relevant variables for our barcelona data frame}

barcelona <- listings %>%  
  select(
         id,
         host_response_rate,
         host_acceptance_rate,
         host_is_superhost,
         host_listings_count,
         host_has_profile_pic,
         host_identity_verified,
         neighbourhood_cleansed,
         has_availability,
         instant_bookable,
         neighbourhood_group_cleansed,
         latitude,
         longitude,
         property_type,
         room_type,
         property_type,
         accommodates,
         bathrooms_text,
         bedrooms,
         beds,
         price,
         minimum_nights,
         maximum_nights,
         availability_30,
         number_of_reviews,
         review_scores_rating,
         review_scores_accuracy,
         review_scores_cleanliness,
         review_scores_checkin,
         review_scores_communication,
         review_scores_location,
         review_scores_value,
         reviews_per_month,
         instant_bookable
         )


# We convert the price from character to numeric
barcelona$price <- as.numeric(gsub("\\$","",barcelona$price))

#We convert bathrooms_text into a variable with an integer number of bathrooms
barcelona$bathrooms <- substr(barcelona$bathrooms_text, 1,2)
barcelona$bathrooms <- as.numeric(gsub("\\.","",barcelona$bathrooms))

#We convert the host_response_rate variable to numeric
barcelona$host_response_rate <- as.numeric(gsub("\\%","",barcelona$host_response_rate))
barcelona$host_acceptance_rate <- as.numeric(gsub("\\%","",barcelona$host_acceptance_rate))

#We convert the host_response_rate variable to numeric
barcelona$host_acceptance_rate <- as.numeric(gsub("\\%","",barcelona$host_acceptance_rate))
barcelona$host_acceptance_rate <- as.numeric(gsub("\\%","",barcelona$host_acceptance_rate))

#omit NA variables
barcelona <- na.omit(barcelona)
skim(barcelona)

```


Having now pulled the specific variables we want to analyse in our data frame and tidy it up a bit, we then proceed to separate property types based on specific subgroups.


```{r, create a categorical variable for property type}
#we group the property types into 5 categories according to frequency distribution to only control for the largest subgroups
barcelona <- barcelona %>%
  mutate(prop_type_simplified = case_when(
    property_type %in% c("Entire rental unit","Private room in rental unit", "Entire serviced apartment","Entire condominium (condo)") ~ property_type, 
    TRUE ~ "Other"
  ))

#We check whether the categorization has been performed correctly
barcelona %>%
  count(property_type, prop_type_simplified) %>%
  arrange(desc(n)) %>% 
  kbl(col.names = c("Property Type", "Category", "Count"),caption = "Count by Property Type") %>% 
  kable_styling() 

#We exclude listings that have minimum nights requirement greater than 4
barcelona <- barcelona %>% 
  filter(minimum_nights<=4)

#Here we categorize the grouped neighbourhoods in Barcelona in 4 different categories: North, Center, Coastal Line, and West
barcelona <- barcelona %>% 
  mutate(neighbourhood_simplified = case_when(
    neighbourhood_group_cleansed %in% c("Horta-Guinardó","Nou Barris","Sarrià-Sant Gervasi") ~ "North",
    neighbourhood_group_cleansed %in% c("Eixample", "Gracia","Ciutat Vella") ~ "Center",
    neighbourhood_group_cleansed %in% c("Sant Martí","Sants-Montjuïc") ~ "Coastal line outside Center",
    TRUE ~ "West"
  ))

barcelona %>%
  count(neighbourhood_group_cleansed, neighbourhood_simplified) %>%
  arrange(desc(n))%>% 
  kbl(col.names = c("Neighbourhood", "Neighbourhood's Category", "Count"),caption = "Count and Category by Neighbourhood") %>% 
  kable_styling()



```


Now, to make our analysis more comprehensive, we further split our data frame into 5 different categories:

- **Host Specific:** Data frame looking specifically at data relating to hosts themselves
- **Property Specific:** Data frame looking at specific characteristics of the properties
- **Reviews Specific:** Data frame looking at how users reviewed specific aspects of these properties and hosts
- **Logical Specific:** Data frame analysing whether listings meet specific requirements
- **Categorical Specific:** Data frame looking at the different neighbourhoods and types of properties we listed above


```{r, create different data frames according to type and content}

host_specific <- barcelona %>% 
  select(host_response_rate,
         host_acceptance_rate,
         host_listings_count
         )

property_specific <- barcelona %>% 
  select(accommodates,
         bedrooms,
         beds,
         bathrooms,
         )

reviews_specific <- barcelona %>% 
  select(number_of_reviews,
         review_scores_accuracy,
         review_scores_checkin,
         review_scores_cleanliness,
         review_scores_location,
         review_scores_communication,
         review_scores_value,
         review_scores_rating
         )

logical_specific <- barcelona %>% 
  select(host_is_superhost,
         host_has_profile_pic,
         host_identity_verified,
         has_availability,
         instant_bookable)

categorical_specific <- barcelona %>% 
  select(neighbourhood_group_cleansed,
         prop_type_simplified,
         room_type)

```


Firstly, we look at the property-related variables, mutate the data frames we created for these to include new variables explaining how well the properties accommodate guests in terms of bathrooms, and then create density charts to visualise the sizes of the properties which we are exploring.

```{r, property related variables and exploratory charts}

property_specific <- property_specific %>% 
  mutate(bathrooms_per_guest=bathrooms/accommodates,
         bedrooms_per_guest=bedrooms/accommodates)


property_specific_longer <- property_specific %>% 
  select(bathrooms_per_guest,
         bedrooms_per_guest,
         bathrooms,
         bedrooms,
         beds,
         accommodates) %>% 
  pivot_longer(names_to="variable_name", values_to="values",everything())

ggplot(property_specific_longer, aes(x=values), na.rm=TRUE)+
  geom_density(fill="grey")+
  facet_wrap(vars(variable_name), scales="free", ncol=3)+
  labs(title="Property related variables affecting prices of Airbnb in Barcelona", x="", y="Density")+
  theme(axis.title = element_text()) + 
  theme(axis.text.y=element_blank())+
  theme_bw()+
  NULL

ggpairs(property_specific)
```


Looking at the distribution, we see that beds and accommodates seem to have a similar distribution. Thus, they might be correlated, if that's the case we should only use one of them for our model. The other distributions are not unified, thus they might have an influence on prices.

In general,  we can see a high positive correlation between bedrooms and beds, roughly 0.8, which suggests that we would better include one of them at a time for our model prediction. There is relatively low negative correlation between bedrooms/ bathrooms and number of bedrooms/ bathrooms per guest. Thus, we could include both at the same time in our model.

```{r, host related variables and explanatory charts}

barcelona$host_response_rate <- barcelona$host_response_rate/100
barcelona$host_acceptance_rate <- barcelona$host_acceptance_rate/100

host_specific <- barcelona %>% 
  select(host_response_rate,
         host_acceptance_rate,
         host_listings_count,
         ) %>% 
  pivot_longer(names_to= "data_names", values_to="data_values", everything())

ggplot(host_specific, aes(x = data_values), na.rm=TRUE) +
  geom_density(fill = "blue") +
  facet_wrap(vars(data_names), scales="free") +
  labs(x = "", y = "Density", title = "Host-Specific Variables affecting Prices of AirBnB in Barcelona") +
  theme_bw() +
  NULL

ggpairs(host_specific)
```


Looking at these charts, we can see that the listings count is very unified, thus it might not influence prices. Acceptance rate seems to be the least unified, hence it could be interesting for our regression model. Last, we can note that the response rate shows a similar pattern to the acceptance rate, so they might be correlated.


```{r, reviews related variables and exploratory charts}

reviews_specific %>%
  pivot_longer(names_to= "data_names", values_to="data_values", everything())%>%
  ggplot(aes(x = data_values), na.rm=TRUE) +
  geom_density(fill = "red",alpha = 0.4) +
  facet_wrap(vars(data_names), scales="free") +
  labs(x = "", y = "Density", title = "Reviews-Specific Variables affecting Prices of AirBnB in Barcelona") +
  theme_bw() +
  NULL


ggpairs(reviews_specific)
```


All the distributions are extremely skewed to the left. Most of them are very unified and might thus not be interesting to include in our model. The least unified variables that could be considered are: review score cleanliness, review score rating and review score value.

From the ggpair, we see there are high positive correlations among pairs of any two of the reviews_specific variables, except for the very first row, number of reviews. This is reasonable because review_scores_cleanliness, review_scores_communication, review_scores_value and review_scores_raing are somehow related to each other. Thus, we would better to include only one of these variables in our model prediction. 
(Note that, although we include both review_scores_rating and review_scores_value in our best model, we would check their collinearity again when we build our model to ensure there is no significant collinear relationships between our variables.)


```{r, logical variables and explanatory table}

#rename logical variables
colnames(logical_specific) <- c("Host is a Superhost", "Host has a Profile Picture", "Host's Identity is Verified", "Property is Available", "Property is Instantly Bookable")

#create table to better visualise logical variables
logical_visualisation <- logical_specific %>%
  
  #pivot table to perform next steps
  pivot_longer(cols = 1:5,
               names_to = "var",
               values_to = "logical") %>% 
  
  #group by variable and logical result (True or False)
  group_by(var, logical) %>%
  
  #count number of True and False for each variable
  summarise(count = n()) %>% 
  
  #pivot wider to have one row per variable and one column for each "True" and "False" count
  pivot_wider(names_from = "logical",
              values_from = "count") %>%
  
  #Format table with kableExtra, renmaing columns, adding title
  kbl(col.names = c("Logical Variable", "Count of True", "Count of False"), caption = "Count of True and False by Logical Variable")%>% 
  kable_styling()


#display table
logical_visualisation

```
 
 
Looking at the above table and considering what each variable represents we can conclude that:
- most flats are not available, this potentially reflects a high demand and could influence prices (for instance the cheapest flats or the flats with the best price/quality balance are probably already booked)
- a majority (~55%) of flats are instantly bookable, however, the distribution of True vs False is the most balanced of all variables. Consequently, this could have an important impact on the price.
- almost all the hosts have a profile picture, thus this probably has no impact on the price.
- a large majority (~80%) of hosts are superhosts, considering that superhosts are hosts who received great ratings, this could have a slight impact on the price.
- a large majority (~80%) of hosts' identities are verified, considering this is an indicator of security, it could slightly influence the price.


```{r, categorical variables and descriptive graphs}

categorical_specific_longer <- categorical_specific %>%
  pivot_longer(names_to="variable_name", values_to="values",everything()) %>% 
  group_by(variable_name,values) %>% 
  mutate(observations=n())

ggplot(categorical_specific_longer, aes(y=reorder(values,observations)),
                                        na.rm=TRUE)+
  geom_bar(fill="grey",orientation = "y")+
  facet_wrap(vars(variable_name), scales="free", ncol=1)+
  labs(title="Categorical variables affecting prices of Airbnb in Barcelona",
             x="", y="Density")+
  theme_bw()+
  NULL

```

We can see that none of the variable is unified, thus they all have the potential to be useful in predicting variability in prices.



# Mapping 

## Map of AirBnBs in Barcelona by Price

```{r, out.width = '80%'}

#we set the color for price to red and create the palette
price_color <- colorNumeric(palette = "Reds",
                            domain = c(1:200),
                            reverse = FALSE)

#We will use the listings data frame for the mapping, so we have to convert price to numeric here as well
listings$price <- as.numeric(gsub("\\$","",listings$price))

#Adding circle markers with popups and colors depending on price range
leaflet(data = filter(listings, minimum_nights <= 4)) %>% 
  addProviderTiles("OpenStreetMap.Mapnik") %>% 
  addCircleMarkers(lng = ~longitude, 
                   lat = ~latitude, 
                   radius = 1, 
                   color = ~price_color(price), 
                   fillOpacity = 0.4, 
                   popup = ~listing_url,
                   label = ~property_type)
```

There is a direct correlation between property prices and proximity to the city center. There appear to be clusters of properties with distinctively higher prices, which could be explained by proximity to touristic locations or transportation connections

```{r, out.width = '80%'}

location_clusters <-leaflet(data = filter(listings, minimum_nights <= 4)) %>%
  
  # Map with OpenStreetMap.Mapnik
  addProviderTiles("OpenStreetMap.Mapnik") %>% 

  # Add circle markers with popups and labels
  addCircleMarkers(lng = ~longitude, 
                   lat = ~latitude, 
                   radius = 1, 
                   fillOpacity=0.6,
                   popup = ~listing_url,
                   label = ~property_type,
                   
                   # cluster 
                   clusterOptions = markerClusterOptions())
#print location_clusters
location_clusters
```

There appears to be a direct correlation between the number of properties and the proximity to the city center. Largest clustering in “Ciutat Vela” and ”Eixample” which are known mainly for their popular tourist spots and renowned architecture. At the same time, areas closer to the center boast easier transportation connections to most Barcelona neighbourhoods and viccinity to nightlife avenues.


# Regression Analysis

## Creating the price_4_nights variable

We create price variable price_4_nights and log it, for our model regression.

```{r}
barcelona_analysis <- barcelona %>% 
  
  #filter for 2 people
  filter(accommodates >= 2) %>%
  
  #calculate price for 4 nights 
  mutate(price_4_nights = price * 4,
         logprice_4_nights = log(price_4_nights))

#create desnity plot
ggplot(data = barcelona_analysis, aes(price_4_nights)) +
  geom_density()+
  #add title and axis titles
  labs(title = "Density Plot of the Price for 2 People for  4 Nights", 
       y = "Density", 
       x = "Price for 2 for 4 Nights")+
  #change theme
  theme_bw()+
  NULL

#create density plot with logarithmic scale
ggplot(data = barcelona_analysis, aes(logprice_4_nights)) +
  geom_density()+
  #add title and axis titles
  labs(title = "Density Plot of the Price for 2 People for 4 Nights - Logarithmic Scale", 
       y = "Density - Logarithmic", 
       x = "Price for 2 for 4 Nights")+
  #change theme
  theme_bw()+
  NULL


```


```{r}

glimpse(barcelona)


correlation_matrix_numeric <- barcelona %>%
  select(host_acceptance_rate,  host_listings_count, latitude, longitude, accommodates, bedrooms, beds, price, minimum_nights, maximum_nights, availability_30, number_of_reviews, review_scores_accuracy, review_scores_cleanliness, review_scores_checkin, review_scores_communication, review_scores_location, review_scores_value, reviews_per_month, bathrooms) %>%
  cor()

corrplot(correlation_matrix_numeric, is.corr = FALSE,
         method="color",
         type="full",
         title="Correlation matrix of numerical variables",
         tl.cex=.6,
         tl.col="black",
         cl.ratio=.3)

Correlation <- cor(correlation_matrix_numeric , use="pairwise.complete.obs")
```



## We will use the normally distributed logprice_4_nights for our analysis.

```{r, Creation of Train and Test}

set.seed(10)
# We create train_test_barcelona that is 75% for training and 25% for testing
train_test_barcelona <- initial_split(barcelona_analysis, prop = 0.75) 
airbnb_listing_train <- training(train_test_barcelona)
airbnb_listing_test <- testing(train_test_barcelona)

```


## Model 1

First, we fit a regression model called `model1` with `logprice_4_nights` as the outcome variable and `prop_type_simplified`, `number_of_reviews`, and `review_scores_rating`as explanatory variables. 

```{r, Model1 creation}
model1 <- lm(logprice_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating, data = barcelona_analysis)
car::vif(model1)

model1 %>% 
  tidy(conf.int = TRUE) %>% 
  mutate(estimate=exp(estimate), 
         std.error = exp(std.error),
         conf.low=exp(conf.low),
         conf.high=exp(conf.high)
         ) %>% 
    kbl(col.names=c("Variable",
                    "Estimate",
                    "SE",
                    "t-stat",
                    "p-value",
                    "Lower CI",
                    "Upper CI")
        ) %>%
  kable_styling()
```

Considering that we use `logprice_4_nights` as our outcome variable. We use exp() to get the estimate, standard error and confidence interval for `price_4_nights`. 

According to the p-value, all the explanatory variables except `prop_type_simplifiedEntire rental unit` are significant.

*review_scores_rating*
- Coefficient of `review_scores_rating` in terms of `price_4_nights` is 1.1153. If `review_scores_rating` increases by 1, `price_4_nights` will increase by 11.53%. 

*prop_type_simplified*
- Coefficient of `prop_type_simplifiedEntire rental unit`, in terms of `price_4_nights` is 0.9784. If property type changes from `Entire condominium (condo)` to `Entire rental unit`, `price_4_nights` will decrease by 2.16%. 
- Coefficient of `prop_type_simplifiedEntire serviced apartment`, in terms of `price_4_nights` is 1.3557. If property type changes from `Entire condominium (condo)` to `Entire serviced apartment`, `price_4_nights` will increase by 35.57%. 
- Coefficient of `prop_type_simplifiedOther`, in terms of `price_4_nights` is 0.6454. If property type changes from `Entire condominium (condo)` to `Other`, `price_4_nights` will decrease by 35.46%. 
- Coefficient of `prop_type_simplifiedPrivate room in rental unit`, in terms of `price_4_nights` is 0.3386. If property type changes from `Entire condominium (condo)` to `Private room in rental unit`, `price_4_nights` will decrease by 66.14%.

```{r, Model 1 Overview}

model1 %>% 
  glance() %>% 
  select(1:6) %>% 
    kbl(col.names=c("R Squared",
                    "Adj. R Squared",
                    "Sigma",
                    "t-stat",
                    "p-value",
                    "Df")
        ) %>%
  kable_styling()

```

```{r, Plotting Model1}

autoplot(model1, 
         alpha = 0.2, 
         label.size = 3) +
  theme_minimal()

```

The adjusted Rsquared of model1 is 0.4395, which means that the selected variables are able to explain 43.95% of the variation in prices. This is a good start but we will run other models and test other variables in order to improve this. Residuals of model1 do not obey Normal Distribution well, we can see some patterns, which let us think that we might be missing key explanatory variables for the prediction of the price.

```{r, Training and Testing for Model1}

#Constructing our predictions for the model and RMSE train from training data
train_rmse <- 
  airbnb_listing_train %>% 
  mutate(predictions = exp(predict(model1, .))) %>% 
  summarise(sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

#Constructing our predictions for the model and RMSE test from testing data
test_rmse <-
  airbnb_listing_test %>% 
  mutate(predictions = exp(predict(model1, .))) %>% 
  summarise(sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

#Training model output on RSquared
train_r_squared <-
  summary(model1)$r.squared

#Testing model output on Rsquared
test_r_squared <-
  cor(predict(model1, airbnb_listing_test), airbnb_listing_test$price_4_nights)

#Creating a matrix from output values
kbl(matrix(c(train_rmse, 
             test_rmse, 
             train_r_squared, 
             test_r_squared),
           nrow = 2,
           dimnames = list(c("Training","Testing"),
                           c("RMSE","RSquared"))),
  ) %>% 
  kable_styling()

```

Difference of RMSE between training data set and testing data set is not very large and the training Rsquared is higher than the testing one.



## Model 2

Then, we want to determine if `room_type` is a significant predictor of the cost for 4 nights, given everything else in the model. We fit model2 with a regression model called `model1` with `logprice_4_nights` as the outcome variable and `prop_type_simplified`, `number_of_reviews`, `review_scores_rating` and `room_rype` as explanatory variables.

```{r, Model2 creation}
model2 <- lm(logprice_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type, data = barcelona_analysis)
car::vif(model2)

model2 %>% 
  tidy(conf.int = TRUE) %>% 
  mutate(estimate=exp(estimate), 
         std.error = exp(std.error),
         conf.low=exp(conf.low),
         conf.high=exp(conf.high)
         ) %>% 
    kbl(col.names=c("Variable",
                    "Estimate",
                    "SE",
                    "t-stat",
                    "p-value",
                    "Lower CI",
                    "Upper CI")
        ) %>%
  kable_styling()
```

According to p-value, `room_type` variables are all significant but `room_typeHotel room`. We see that changes to Hotel, Private or Shared room will result in a decrease in price of 3.8%, 46.9% and 71.4% respectively. This is coherent with what we would expect.

```{r, Model 2 Overview}

model2 %>% 
  glance() %>% 
  select(1:6) %>% 
    kbl(col.names=c("R Squared",
                    "Adj. R Squared",
                    "Sigma",
                    "t-stat",
                    "p-value",
                    "Df")
        ) %>%
  kable_styling()

```

```{r, Plotting Model2}

autoplot(model2, 
         alpha = 0.2, 
         label.size = 3) +
  theme_minimal()

```

The adjusted Rsquared of model2 is 0.4718, which means that the selected variables are able to explain 47.18%% of the variation in prices. This is an improvement compared to model1 (43.95%). Residuals of model2 do not obey Normal Distribution well, we can see some patterns as for model2, which let us think that we might still be missing key explanatory variables for the prediction of the price.

```{r, Training and Testing for Model2}

#Constructing our predictions for the model and RMSE train from training data
train_rmse <- 
  airbnb_listing_train %>% 
  mutate(predictions = exp(predict(model2, .))) %>% 
  summarise(sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

#Constructing our predictions for the model and RMSE test from testing data
test_rmse <-
  airbnb_listing_test %>% 
  mutate(predictions = exp(predict(model2, .))) %>% 
  summarise(sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

#Training model output on RSquared
train_r_squared <-
  summary(model2)$r.squared

#Testing model output on Rsquared
test_r_squared <-
  cor(predict(model2, airbnb_listing_test), airbnb_listing_test$price_4_nights)

#Creating a matrix from output values
kbl(matrix(c(train_rmse, 
             test_rmse, 
             train_r_squared, 
             test_r_squared),
           nrow = 2,
           dimnames = list(c("Training","Testing"),
                           c("RMSE","RSquared"))),
  ) %>% 
  kable_styling()

```

Difference of RMSE between training data set and testing data set is not very large and the training Rsquared is higher than the testing one.


## Model 3

Our dataset has many more variables, so we are trying to find whether other variables are significant predictors of `price_4_nights`.

We want to know if `bathrooms`, `bedrooms`, `beds`, `accomodates` are significant predictors of `price_4_nights`. We fit model3 with a regression model called `model1` with `logprice_4_nights` as the outcome variable and `prop_type_simplified`, `number_of_reviews`, `review_scores_rating`, `room_rype`, `bathrooms`, `bedrooms`, `beds` and `accomodates`as explanatory variables.

```{r, Creation of Model 3}
model3 <- lm(logprice_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bathrooms + bedrooms + beds + accommodates, 
             data = barcelona_analysis)
car::vif(model3)

model3 %>% 
  tidy(conf.int = TRUE) %>% 
  mutate(estimate=exp(estimate), 
         std.error = exp(std.error),
         conf.low=exp(conf.low),
         conf.high=exp(conf.high)
         ) %>% 
    kbl(col.names=c("Variable",
                    "Estimate",
                    "SE",
                    "t-stat",
                    "p-value",
                    "Lower CI",
                    "Upper CI")
        ) %>%
  kable_styling()
```

According to the p-value, `beds` is non-significant variable and we should remove it from the model. Other variables are significant.
An increase (by 1) in the number of `accomodates`, `bedrooms` and `bathrooms`all result in an increase in price of 6.99%, 4.38% and 14.48% respectively.


To make GVIFs comparable across variables, we can use the Square of GVIF^(1/(2*DF)).  This reduces GVIF to a linear measure.  If the calculated value is less than 5, then we can conclude that their is no collinearity. `accomodates` has Square of (2.352034)^2 = 5.7 >5, indicating collinearity. Therefore, we need to remove it from the model.

```{r, Model 3 Overview}

model3 %>% 
  glance() %>% 
  select(1:6) %>% 
    kbl(col.names=c("R Squared",
                    "Adj. R Squared",
                    "Sigma",
                    "t-stat",
                    "p-value",
                    "Df")
        ) %>%
  kable_styling()

```

```{r, Plotting Model3}

autoplot(model3, 
         alpha = 0.2, 
         label.size = 3) +
  theme_minimal()

```
The adjusted Rsquared of model3 is 0.5848, which means that the selected variables are able to explain 58.48% of the variation in prices. This is an improvement compared to model2 (47.18%). Residuals of model2 roughly obey Normal Distribution well, we can see less patterns than for model2, but we might still be missing explanatory variables to improve the prediction of the price.

```{r, Training and Testing for Model3}

#Constructing our predictions for the model and RMSE train from training data
train_rmse <- 
  airbnb_listing_train %>% 
  mutate(predictions = exp(predict(model3, .))) %>% 
  summarise(sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

#Constructing our predictions for the model and RMSE test from testing data
test_rmse <-
  airbnb_listing_test %>% 
  mutate(predictions = exp(predict(model3, .))) %>% 
  summarise(sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

#Training model output on RSquared
train_r_squared <-
  summary(model3)$r.squared

#Testing model output on Rsquared
test_r_squared <-
  cor(predict(model3, airbnb_listing_test), airbnb_listing_test$price_4_nights)

#Creating a matrix from output values
kbl(matrix(c(train_rmse, 
             test_rmse, 
             train_r_squared, 
             test_r_squared),
           nrow = 2,
           dimnames = list(c("Training","Testing"),
                           c("RMSE","RSquared"))),
  ) %>% 
  kable_styling()

```

Difference of RMSE between training data set and testing data set is very small and the testing Rsquared is higher than the training one, which might imply slight overfitting, i.e. our model is becoming very complex.


## Model 4

We want to know if `host_is_superhost`commands a pricing premium, after controlling for other variables. We fit model4 with a regression model called `model4` with `logprice_4_nights` as the outcome variable and `prop_type_simplified`, `number_of_reviews`, `review_scores_rating`, `room_rype`, `bathrooms`, and `host_is_superhost`as explanatory variables.

```{r, Model 4 Creation}
model4 <- lm(logprice_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bathrooms + host_is_superhost, 
             data = barcelona_analysis)
car::vif(model4)

model4 %>% 
  tidy(conf.int = TRUE) %>% 
  mutate(estimate=exp(estimate), 
         std.error = exp(std.error),
         conf.low=exp(conf.low),
         conf.high=exp(conf.high)
         ) %>% 
    kbl(col.names=c("Variable",
                    "Estimate",
                    "SE",
                    "t-stat",
                    "p-value",
                    "Lower CI",
                    "Upper CI")
        ) %>%
  kable_styling()
```
According to the p-value, `host_is_superhost`is significant. It also commands a small pricing premium, after controlling for other variables (4.48%).

```{r, Model 4 Overview}

model4 %>% 
  glance() %>% 
  select(1:6) %>% 
    kbl(col.names=c("R Squared",
                    "Adj. R Squared",
                    "Sigma",
                    "t-stat",
                    "p-value",
                    "Df")
        ) %>%
  kable_styling()

```

```{r, Plotting Model4}

autoplot(model4, 
         alpha = 0.2, 
         label.size = 3) +
  theme_minimal()

```
The adjusted Rsquared of model4 is 0.5524, which means that the selected variables are able to explain 55.24% of the variation in prices. This is a decrease compared to model3 (58.48%), meaning that `host_is_superhost` should probably not be included. Residuals of model4 display patterns again, which let us think that we might still be missing key explanatory variables for the prediction of the price.

```{r, Training and Testing for Model4}

#Constructing our predictions for the model and RMSE train from training data
train_rmse <- 
  airbnb_listing_train %>% 
  mutate(predictions = exp(predict(model4, .))) %>% 
  summarise(sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

#Constructing our predictions for the model and RMSE test from testing data
test_rmse <-
  airbnb_listing_test %>% 
  mutate(predictions = exp(predict(model4, .))) %>% 
  summarise(sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

#Training model output on RSquared
train_r_squared <-
  summary(model4)$r.squared

#Testing model output on Rsquared
test_r_squared <-
  cor(predict(model4, airbnb_listing_test), airbnb_listing_test$price_4_nights)

#Creating a matrix from output values
kbl(matrix(c(train_rmse, 
             test_rmse, 
             train_r_squared, 
             test_r_squared),
           nrow = 2,
           dimnames = list(c("Training","Testing"),
                           c("RMSE","RSquared"))),
  ) %>% 
  kable_styling()

```

Difference of RMSE between training data set and testing data set is very small and the testing Rsquared is higher than the training one, which might imply slight overfitting, i.e. our model is becoming very complex.

## Model 5

```{r, Creation of Model5}
model5 <- lm(logprice_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bathrooms +  instant_bookable, 
             data = barcelona_analysis)
car::vif(model5)

model5 %>% 
  tidy(conf.int = TRUE) %>% 
  mutate(estimate=exp(estimate), 
         std.error = exp(std.error),
         conf.low=exp(conf.low),
         conf.high=exp(conf.high)
         ) %>% 
    kbl(col.names=c("Variable",
                    "Estimate",
                    "SE",
                    "t-stat",
                    "p-value",
                    "Lower CI",
                    "Upper CI")
        ) %>%
  kable_styling()
```
`instant_bookable` is significant according to its p-value. Also a change in that logical variable from False to True results in and 5.22% increase in price.

```{r, Model5 Overview}

model5 %>% 
  glance() %>% 
  select(1:6) %>% 
    kbl(col.names=c("R Squared",
                    "Adj. R Squared",
                    "Sigma",
                    "t-stat",
                    "p-value",
                    "Df")
        ) %>%
  kable_styling()

```

```{r, Plotting Model5}

autoplot(model5, 
         alpha = 0.2, 
         label.size = 3) +
  theme_minimal()

```
The adjusted Rsquared of model5 is 0.5532, which means that the selected variables are able to explain 55.32% of the variation in prices. This is a slight increase compared to model4 (55.24%), meaning that `instant_bookable` should probably be included. Residuals of model5 still display patterns, which let us think that we might still be missing key explanatory variables for the prediction of the price.

```{r, Training and Testing for Model5}

#Constructing our predictions for the model and RMSE train from training data
train_rmse <- 
  airbnb_listing_train %>% 
  mutate(predictions = exp(predict(model5, .))) %>% 
  summarise(sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

#Constructing our predictions for the model and RMSE test from testing data
test_rmse <-
  airbnb_listing_test %>% 
  mutate(predictions = exp(predict(model5, .))) %>% 
  summarise(sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

#Training model output on RSquared
train_r_squared <-
  summary(model5)$r.squared

#Testing model output on Rsquared
test_r_squared <-
  cor(predict(model5, airbnb_listing_test), airbnb_listing_test$price_4_nights)

#Creating a matrix from output values
kbl(matrix(c(train_rmse, 
             test_rmse, 
             train_r_squared, 
             test_r_squared),
           nrow = 2,
           dimnames = list(c("Training","Testing"),
                           c("RMSE","RSquared"))),
  ) %>% 
  kable_styling()

```

Difference of RMSE between training data set and testing data set is very small and the testing Rsquared is higher than the training one, which might imply slight overfitting, i.e. our model is becoming very complex.


## Model 6


```{r}
model6 <- lm(logprice_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bathrooms + instant_bookable + neighbourhood_simplified, 
             data = barcelona_analysis)
car::vif(model6)

model6 %>% 
  tidy(conf.int = TRUE) %>% 
  mutate(estimate=exp(estimate), 
         std.error = exp(std.error),
         conf.low=exp(conf.low),
         conf.high=exp(conf.high)
         ) %>% 
    kbl(col.names=c("Variable",
                    "Estimate",
                    "SE",
                    "t-stat",
                    "p-value",
                    "Lower CI",
                    "Upper CI")
        ) %>%
  kable_styling()
```
The `neighbourhood` variables are all significant according to p-value. Changing to North, Coastal outside Center or West will induce a decrease in price of 18.29%, 13.20%, 13.24% respectively.

```{r, Model6 Overview}

model6 %>% 
  glance() %>% 
  select(1:6) %>% 
    kbl(col.names=c("R Squared",
                    "Adj. R Squared",
                    "Sigma",
                    "t-stat",
                    "p-value",
                    "Df")
        ) %>%
  kable_styling()

```

```{r, Plotting Model6}

autoplot(model6, 
         alpha = 0.2, 
         label.size = 3) +
  theme_minimal()

```
The adjusted Rsquared of model6 is 0.5659, which means that the selected variables are able to explain 56.59% of the variation in prices. This is a slight increase compared to model5 (55.32%), meaning that `neighbourhood` variables should probably be included. Residuals of model5 still display patterns but less, which let us think that we might still be missing key explanatory variables for the prediction of the price.

```{r, Training and Testing for Model6}

#Constructing our predictions for the model and RMSE train from training data
train_rmse <- 
  airbnb_listing_train %>% 
  mutate(predictions = exp(predict(model6, .))) %>% 
  summarise(sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

#Constructing our predictions for the model and RMSE test from testing data
test_rmse <-
  airbnb_listing_test %>% 
  mutate(predictions = exp(predict(model6, .))) %>% 
  summarise(sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

#Training model output on RSquared
train_r_squared <-
  summary(model6)$r.squared

#Testing model output on Rsquared
test_r_squared <-
  cor(predict(model6, airbnb_listing_test), airbnb_listing_test$price_4_nights)

#Creating a matrix from output values
kbl(matrix(c(train_rmse, 
             test_rmse, 
             train_r_squared, 
             test_r_squared),
           nrow = 2,
           dimnames = list(c("Training","Testing"),
                           c("RMSE","RSquared"))),
  ) %>% 
  kable_styling()

```

Difference of RMSE between training data set and testing data set is very small and the testing Rsquared is higher than the training one, which might imply slight overfitting, i.e. our model is becoming very complex.


## Model 7

We want to know the effect of `avalability_30` or `reviews_per_month` on `price_4_nights`, after we control for other variables.

```{r, Creation of Model7}

model7 <- lm(logprice_4_nights ~ prop_type_simplified + number_of_reviews + review_scores_rating + room_type + bathrooms + instant_bookable + neighbourhood_simplified + availability_30 + reviews_per_month,
             data = barcelona_analysis)
car::vif(model7)

model7 %>% 
  tidy(conf.int = TRUE) %>% 
  mutate(estimate=exp(estimate), 
         std.error = exp(std.error),
         conf.low=exp(conf.low),
         conf.high=exp(conf.high)
         ) %>% 
    kbl(col.names=c("Variable",
                    "Estimate",
                    "SE",
                    "t-stat",
                    "p-value",
                    "Lower CI",
                    "Upper CI")
        ) %>%
  kable_styling()
```

`avalability_30` and `reviews_per_month`are both significant according to p-value. Surprisingly an increase in `reviews_per_month` results in a 4.17% decrease in price. Increase in availability only results in a very slight increase in price.


```{r, Model7 Overview}

model7 %>% 
  glance() %>% 
  select(1:6) %>% 
    kbl(col.names=c("R Squared",
                    "Adj. R Squared",
                    "Sigma",
                    "t-stat",
                    "p-value",
                    "Df")
        ) %>%
  kable_styling()

```


```{r, Plotting Model7}

autoplot(model7, 
         alpha = 0.2, 
         label.size = 3) +
  theme_minimal()

```
The adjusted Rsquared of model7 is 0.5892, which means that the selected variables are able to explain 58.92% of the variation in prices. This is a slight increase compared to model6 (56.59%), meaning that `avalability_30` and `reviews_per_month` should probably be included. Residuals of model7 show an improvement, close to Normal Distribution and less patterns, which is good, howver we might still be able to improve the price's prediction.

```{r, Training and Testing for Model7}

#Constructing our predictions for the model and RMSE train from training data
train_rmse <- 
  airbnb_listing_train %>% 
  mutate(predictions = exp(predict(model7, .))) %>% 
  summarise(sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

#Constructing our predictions for the model and RMSE test from testing data
test_rmse <-
  airbnb_listing_test %>% 
  mutate(predictions = exp(predict(model7, .))) %>% 
  summarise(sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

#Training model output on RSquared
train_r_squared <-
  summary(model7)$r.squared

#Testing model output on Rsquared
test_r_squared <-
  cor(predict(model7, airbnb_listing_test), airbnb_listing_test$price_4_nights)

#Creating a matrix from output values
kbl(matrix(c(train_rmse, 
             test_rmse, 
             train_r_squared, 
             test_r_squared),
           nrow = 2,
           dimnames = list(c("Training","Testing"),
                           c("RMSE","RSquared"))),
  ) %>% 
  kable_styling()

```
Difference of RMSE between training data set and testing data set is not very large and the training Rsquared is now higher than the testing one, which is a good sign.


# Best Model

## Setting and Analysis

```{r, best model}
best_model <- lm(logprice_4_nights ~ prop_type_simplified + review_scores_rating + room_type + bathrooms + bedrooms + accommodates + instant_bookable + neighbourhood_simplified + availability_30 + reviews_per_month + host_is_superhost + host_response_rate + host_acceptance_rate + review_scores_cleanliness + review_scores_checkin + review_scores_location + review_scores_value,
             data = barcelona_analysis)
msummary(best_model)
car::vif(best_model)

best_model %>% 
  tidy(conf.int = TRUE) %>% 
  mutate(estimate=exp(estimate), 
         std.error = exp(std.error),
         conf.low=exp(conf.low),
         conf.high=exp(conf.high)
         ) %>% 
    kbl(col.names=c("Variable",
                    "Estimate",
                    "SE",
                    "t-stat",
                    "p-value",
                    "Lower CI",
                    "Upper CI")
        ) %>%
  kable_styling()
```
All variables but `prop_type_simplifiedEntire rental unit`, `prop_type_simplifiedOther` and `room_typeHotel room` are significant according to their p-values. Changes in these variables all result in either a decrease or an increase in price, which is more or less important.


```{r, best_model Overview}

best_model %>% 
  glance() %>% 
  select(1:6) %>% 
    kbl(col.names=c("R Squared",
                    "Adj. R Squared",
                    "Sigma",
                    "t-stat",
                    "p-value",
                    "Df")
        ) %>%
  kable_styling()

```


```{r, Plotting best_model}

autoplot(best_model, 
         alpha = 0.2, 
         label.size = 3) +
  theme_minimal()

```
The adjusted Rsquared of our best model is 0.6225, which means that the selected variables are able to explain 62.25% of the variation in prices. This is a very good prediction model, higher than all models 1 to 7 that we obtained before. Moreover, the residuals of the model approximately follow a Normal Distribution, there is no clear pattern in the residuals. Thus, it seems that this model includes all key outcome variables to obtain a regression model that provides a good prediction of the analysed price.

```{r, Training and Testing for Best Model}

#Constructing our predictions for the model and RMSE train from training data
train_rmse <- 
  airbnb_listing_train %>% 
  mutate(predictions = exp(predict(best_model, .))) %>% 
  summarise(sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

#Constructing our predictions for the model and RMSE test from testing data
test_rmse <-
  airbnb_listing_test %>% 
  mutate(predictions = exp(predict(best_model, .))) %>% 
  summarise(sqrt(sum(predictions - price_4_nights)**2/n())) %>% 
  pull()

#Training model output on RSquared
train_r_squared <-
  summary(best_model)$r.squared

#Testing model output on Rsquared
test_r_squared <-
  cor(predict(best_model, airbnb_listing_test), airbnb_listing_test$price_4_nights)

#Creating a matrix from output values
kbl(matrix(c(train_rmse, 
             test_rmse, 
             train_r_squared, 
             test_r_squared),
           nrow = 2,
           dimnames = list(c("Training","Testing"),
                           c("RMSE","RSquared"))),
  ) %>% 
  kable_styling()

```

Difference of RMSE between training data set and testing data set is not very large and the training Rsquared is higher than the testing one, thus we do not have overfitting issues in our model.


## Diagnostics, collinearity, summary tables


```{r}
huxreg(model1, model2, model3, model4, model5, model6, model7, best_model,
       coefs=c("Property Type - Entire Unit"="prop_type_simplifiedEntire rental unit",
               "Property Type - Entire Unit"="prop_type_simplifiedEntire serviced apartment",
               "Property Type - Entire Unit"="prop_type_simplifiedPrivate room in rental unit",
               "Property Type - Entire Unit"="prop_type_simplifiedOther",
               "Number of Reviews"="number_of_reviews",
               "Rating Score" = "review_scores_rating",
               "Room Type - Hotel" = "room_typeHotel room",
               "Room Type - Private Room"="room_typePrivate room",
               "Room Type - Shared Room"="room_typeShared room",
               "Number of Bathrooms"="bathrooms",
               "Number of Bedrooms"="bedrooms",
               "Number of Beds"="beds",
               "Accommodates"="accommodates",
               "Host is Superhost - TRUE"="host_is_superhostTRUE",
               "Instant Bookable - TRUE"="instant_bookableTRUE",
               "Neighbourhood - Coastal Line outside Center" = "neighbourhood_simplifiedCoastal line outside Center",
               "Neighbourhood - West"="neighbourhood_simplifiedWest",
               "Neighbourhood - North"="neighbourhood_simplifiedNorth",
               "Availability next 30 days" = "availability_30",
               "Reviews per month" = "reviews_per_month"))

```

The best model is preferable to other choices, as it offers the highest Rsquared, does not present any overfitting issue and has residuals that do not show clear patterns. In conclusion, it includes the most important outcome variables and enables good prediction of the variable of interest which is the price.

## Prediction

In this last part, we use our best model to predict the total cost of an Airbnb accommodation for a visit in Barcelona  over reading week. More specifically, we want Airbnb's in Barcelona that are apartments with a private room, have at least 10 reviews, and an average rating of at least 90. 

```{r}
# we select: an Entire serviced apartment, which has at least 10 reviews, and an average rating of at least 4,5/5 to conduct our prediction
finally_done <- barcelona_analysis %>% 
  filter(property_type == 'Entire serviced apartment',
         review_scores_rating >= 4.5,
         number_of_reviews >= 10) %>% 
  
  # we take the exponential for prediction because we used log(y) in our model
  mutate(prediction = exp(predict(best_model, .)))

```

```{r}
# we construct a confidence interval
upper_ci <- quantile(finally_done$prediction, 0.975)
lower_ci <- quantile(finally_done$prediction, 0.025)

# we calculate the mean
average_prediction <- mean(finally_done$prediction)

# we visualise
ggplot(finally_done, aes(x = prediction)) +
  geom_histogram() +
  geom_vline(xintercept = average_prediction, size = 0.7, color = 'red') + 
  geom_vline(xintercept = upper_ci, size = 0.7, color = 'blue') +
  geom_vline(xintercept = lower_ci, size = 0.7, color = 'blue')  +
  labs(y = "count", x = "Price: 2 Guests for 4 Nights", 
       title = 'Estimate and CI for the Price of a Stay in a Barcelona AirBnB',
       subtitle = 'Histogram of the Estimated Price') +
  scale_x_continuous()+
  theme_bw()+
  NULL
```

## Recommendations and Next Steps

After reaching the conclusion of our case-study, we recommend the couple to travel to Barcelona and select a property that has at least a 4.5* rating, has more than 10 reviews in total, and is an entire serviced apartment. These are the best predictors of price and will give the most satisfying experience to the couple.

For future analysis, we would recommend introducing a following variable that we would call "proximity_to_center". Based on our Heat and Cluster Map, we see that the closer the property is located to the center of Barcelona, the more expensive the 4 night rate is. We can also see on the cluster map, that the more central the location is the more properties there are available. Creating this variable could be done through coming up a new variable using the combination of longitude and latitude points. I believe that this would have significant explanatory power in predicting price.

We also have to be mindful, that the Covid-19 Pandemic distorted the data-set a lot, so in the future, we would want to exclude those datapoints from the set in order to exclude outliers and bias from our data set. To eliminate even more bias from the data-set it is imperative to understand that the houseing market, especially the rental one, is cyclical, with a lot of cyclicality, such as summer and christmas season and over the weekends and public holidays. This could be mitigate by introducing variables that account for cyclicality, or taking long-term period averages that could smooth out high and low periods in the market.

Finally, this is publicly sourced data, that is on the the market uploaded by all kinds of individuals, with a lot of oversight, but fake, scam listings can always make it through the filters. We do not know how these points are treated, nor whether they are removed from the dataset after they have been discovered. This leads to possibly false data, that could further bias our predictions.
  
# Acknowledgements

- The data for this project is from [insideairbnb.com](insideairbnb.com)